# Kafka为什么很快？
Kafka利用操作系统特性做了很多优化

1、消除了磁盘的不良访问模式，避免随机访问磁盘而采用顺序访问磁盘。顺序访问磁盘甚至比随机访问内存还要快。

2、避免过多的小型IO操作，过多的小型IO操作不仅出现在客户端和服务器之间，也发生在服务器自己的持久化操作中。为了避免这种情况，Kafka的协议是围绕“消息集”抽象构建的，该抽象自然地将消息组合在一起。这允许网络请求将消息组合在一起并分摊网络往返的开销，而不是一次发送单个消息。服务器依次将消息块一次性附加到其日志中，而消费者一次获取大的线性块。这种简单的优化会产生数量级的加速。批处理导致更大的网络数据包、更大的顺序磁盘操作、连续的内存块等等，所有这些都允许 Kafka将突发的随机消息写入流转换为流向消费者的线性写入。

3、避免过多的字节复制，Kafka采用了由生产者、代理和消费者共享的标准化二进制消息格式（因此数据块可以在它们之间传输而无需修改）。

代理维护的消息日志本身只是一个文件目录，每个文件都由一系列消息集填充，这些消息集以生产者和消费者使用的相同格式写入磁盘。保持这种通用格式可以优化最重要的操作：持久日志块的网络传输。现代 Unix 操作系统提供了一个高度优化的代码路径，用于将数据从页面缓存传输到套接字；在 Linux 中，这是通过 sendfile 系统调用完成的。

要了解 sendfile 的影响，重要的是要了解将数据从文件传输到套接字的常用数据路径：

操作系统从磁盘读取数据到内核空间的pagecache中
应用程序从内核中读取数据到用户空间缓冲区
应用程序将数据写回内核空间到套接字缓冲区
操作系统将数据从套接字缓冲区复制到 NIC 缓冲区，然后通过网络发送
这显然是低效的，有四个副本和两个系统调用。使用 sendfile，通过允许操作系统将数据从页面缓存直接发送到网络来避免这种重新复制。所以在这个优化的路径中，只需要最终复制到 NIC 缓冲区。

4、高效的压缩方式
有效的压缩需要将多条消息一起压缩，而不是单独压缩每条消息。

Kafka 通过高效的批处理格式支持这一点。一批消息可以聚集在一起压缩并以这种形式发送到服务器。这批消息会以压缩的形式写入，并且会在日志中保持压缩状态，只会被消费者解压。

# topic
Kafka的主题被划分为一组完全有序的分区，每个分区在任何给定时间由每个订阅消费者组中的一个消费者消费。这意味着消费者在每个分区中的位置只是一个整数，即下一条要消费的消息的偏移量。这使得关于消耗的状态非常小，每个分区只有一个数字。

# go
Go 内存模型指定了在何种条件下，一个 goroutine 中的变量读取可以保证观察到不同 goroutine 中对同一变量的写入所产生的值。

go的runtime能力：内存管理、垃圾回收、协程调度、有一定的屏蔽系统调用的能力（支撑跨平台）、
一些go的关键字其实就是runtime下的函数：
    go->newproc
    new->newobject
    make->makeslice\makechain\makemap
    <-->chansend1\chanrecv1
go的runtime被编译为用户程序的一部分。

go程序的执行过程：
    1、初始化g0执行栈，g0是为了调度协程而产生的协程，是每个go程序的第一个协程。
    2、运行时检测
    3、初始化参数、操作系统参数、调度器参数。
    4、创建主协程，执行runtime.main,放入调度器、等待调度。
    5、初始化M，用来调度主协程。
    6、主协程执行主函数：执行runtime包的init方法、启动垃圾收集器、执行用户包依赖的init方法、执行用户主函数main.main()

go关于面向对象的讨论：
    go没有对象、没有类、没有继承，go通过组合匿名字段来达到类似继承的效果，保留了基本的面向对象的特性。支持面向对象的编程风格。



# kafka-go
similar to Kafka with go version
